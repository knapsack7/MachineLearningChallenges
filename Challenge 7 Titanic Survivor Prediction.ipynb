{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head(n=10)# Survived is the final value output values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The features which are not useful\n",
    "columns_to_drop=[\"name\",\"boat\",\"ticket\",\"body\",\"cabin\",\"embarked\",\"home.dest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data.drop(columns_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_format=pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 2)\n"
     ]
    }
   ],
   "source": [
    "print(submission_format.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(submission_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data_clean[\"sex\"] = le.fit_transform(data_clean[\"sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Imputation\n",
    "data_clean = data_clean.fillna(data_clean[\"age\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.838978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.838978</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived  sex        age  sibsp  parch    fare\n",
       "0     3.0       0.0    0  29.838978    0.0    0.0   7.750\n",
       "1     2.0       0.0    1  39.000000    0.0    0.0  26.000\n",
       "2     2.0       1.0    0  40.000000    0.0    0.0  13.000\n",
       "3     3.0       1.0    0  31.000000    1.0    1.0  20.525\n",
       "4     3.0       1.0    0  29.838978    2.0    0.0  23.250"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1009, 6) (1009, 1)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Separating columns for training(input_cols) and validating(output_cols)  \n",
    "input_cols = ['pclass',\"sex\",\"age\",\"sibsp\",\"parch\",\"fare\"]\n",
    "output_cols = [\"survived\"]\n",
    "\n",
    "X = data_clean[input_cols]\n",
    "Y = data_clean[output_cols]\n",
    "\n",
    "print(X.shape,Y.shape)\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(col):\n",
    "    # No of unique values in that column\n",
    "    # counts is a tuple\n",
    "    counts = np.unique(col,return_counts=True)\n",
    "    # Total number of entries in that column\n",
    "    N = float(col.shape[0])\n",
    "    \n",
    "    ent = 0.0\n",
    "    \n",
    "    for ix in counts[1]:\n",
    "        p  = ix/N\n",
    "        ent += (p*np.log2(p))\n",
    "    \n",
    "    return -1.0*ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fkey is the name of column and fval is the threshold value(mean of values in that column)\n",
    "# if value in column is greater than fval(threshold) it will belong to one node and otherwise\n",
    "def divide_data(x_data,fkey,fval):\n",
    "    #Work with Pandas Data Frames\n",
    "    #Creating two empty data files\n",
    "    x_right = pd.DataFrame([],columns=x_data.columns)\n",
    "    x_left = pd.DataFrame([],columns=x_data.columns)\n",
    "    \n",
    "    for ix in range(x_data.shape[0]):\n",
    "        val = x_data[fkey].loc[ix]\n",
    "        \n",
    "        if val > fval:\n",
    "            x_right = x_right.append(x_data.loc[ix])\n",
    "        else:\n",
    "            x_left = x_left.append(x_data.loc[ix])\n",
    "            \n",
    "    return x_left,x_right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(x_data,fkey,fval):\n",
    "    \n",
    "    left,right = divide_data(x_data,fkey,fval)\n",
    "    \n",
    "    #% of total samples are on left and right\n",
    "    l = float(left.shape[0])/x_data.shape[0]\n",
    "    r = float(right.shape[0])/x_data.shape[0]\n",
    "    \n",
    "    #All examples come to one side!\n",
    "    if left.shape[0] == 0 or right.shape[0] ==0:\n",
    "        return -1000000 #Min Information Gain\n",
    "    # Survived column is used for entropy calculation\n",
    "    i_gain = entropy(x_data.survived) - (l*entropy(left.survived)+r*entropy(right.survived))\n",
    "    return i_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pclass\n",
      "0.055456910002982474\n",
      "sex\n",
      "0.19274737190850932\n",
      "age\n",
      "0.0010525742338489685\n",
      "sibsp\n",
      "0.006492394392888956\n",
      "parch\n",
      "0.019756080122948272\n",
      "fare\n",
      "0.04242793401428169\n"
     ]
    }
   ],
   "source": [
    "# Test our function\n",
    "for fx in X.columns:\n",
    "    print(fx)\n",
    "    print(information_gain(data_clean,fx,data_clean[fx].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth=5 it is not allowed that tree goes to maximum depth possible bz if it grows to fullest it may\n",
    "# lead to the case of overfitting leading to the poor generalisation\n",
    "class DecisionTree:\n",
    "    \n",
    "    #Constructor\n",
    "    def __init__(self,depth=0,max_depth=4):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        # feature about which split will be performed\n",
    "        self.fkey = None\n",
    "        # threshold value for the feature\n",
    "        self.fval = None\n",
    "        self.max_depth = max_depth\n",
    "        self.depth = depth\n",
    "        # what i am goint to predict at this node\n",
    "        self.target = None\n",
    "        \n",
    "    def train(self,X_train):\n",
    "        \n",
    "        features = ['pclass','sex','age','sibsp', 'parch', 'fare']\n",
    "        info_gains = []\n",
    "        \n",
    "        for ix in features:\n",
    "            i_gain = information_gain(X_train,ix,X_train[ix].mean())\n",
    "            info_gains.append(i_gain)\n",
    "        # extractimg the columns that defines max information gain  \n",
    "        self.fkey = features[np.argmax(info_gains)]\n",
    "        # setting that fval for the current node in the decision tree\n",
    "        self.fval = X_train[self.fkey].mean()\n",
    "        print(\"Making Tree Features is\",self.fkey)\n",
    "        \n",
    "        #Split Data\n",
    "        data_left,data_right = divide_data(X_train,self.fkey,self.fval)\n",
    "        data_left = data_left.reset_index(drop=True)\n",
    "        data_right = data_right.reset_index(drop=True)\n",
    "         \n",
    "        #Truly a left node\n",
    "        if data_left.shape[0]  == 0 or data_right.shape[0] ==0:\n",
    "            if X_train.survived.mean() >= 0.5:\n",
    "                self.target = \"survive\"\n",
    "            else:\n",
    "                self.target = \"dead\"\n",
    "            return\n",
    "        #Stop earyly when depth >=max depth\n",
    "        if(self.depth>=self.max_depth):\n",
    "            if X_train.survived.mean() >= 0.5:\n",
    "                self.target = \"survive\"\n",
    "            else:\n",
    "                self.target = \"dead\"\n",
    "            return\n",
    "        \n",
    "        #Recursive Case\n",
    "        self.left = DecisionTree(depth=self.depth+1,max_depth=self.max_depth)\n",
    "        self.left.train(data_left)\n",
    "        \n",
    "        self.right = DecisionTree(depth=self.depth+1,max_depth=self.max_depth)\n",
    "        self.right.train(data_right)\n",
    "        \n",
    "        #You can set the target at every node\n",
    "        if X_train.survived.mean() >= 0.5:\n",
    "            self.target = \"survive\"\n",
    "        else:\n",
    "            self.target = \"dead\"\n",
    "        return\n",
    "    \n",
    "    def predict(self,test):\n",
    "        if test[self.fkey]>self.fval:\n",
    "            #go to right\n",
    "            if self.right is None:\n",
    "                return self.target\n",
    "            return self.right.predict(test)\n",
    "        else:\n",
    "            if self.left is None:\n",
    "                return self.target\n",
    "            return self.left.predict(test)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Tree Features is sex\n",
      "Making Tree Features is pclass\n",
      "Making Tree Features is pclass\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is sibsp\n",
      "Making Tree Features is sibsp\n",
      "Making Tree Features is parch\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is age\n",
      "Making Tree Features is parch\n",
      "Making Tree Features is sibsp\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is age\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is parch\n",
      "Making Tree Features is age\n",
      "Making Tree Features is fare\n",
      "Making Tree Features is sibsp\n",
      "Making Tree Features is age\n",
      "Making Tree Features is pclass\n",
      "Making Tree Features is parch\n",
      "Making Tree Features is pclass\n",
      "Making Tree Features is age\n",
      "Making Tree Features is parch\n",
      "Making Tree Features is sibsp\n",
      "Making Tree Features is sibsp\n",
      "Making Tree Features is sibsp\n",
      "Making Tree Features is age\n"
     ]
    }
   ],
   "source": [
    "dt.train(data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv(\"Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"sex\"] = le.fit_transform(test_data[\"sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop=[\"name\",\"boat\",\"ticket\",\"body\",\"cabin\",\"embarked\",\"home.dest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_clean=test_data.drop(columns_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 6 columns):\n",
      "pclass    300 non-null float64\n",
      "sex       300 non-null int64\n",
      "age       234 non-null float64\n",
      "sibsp     300 non-null float64\n",
      "parch     300 non-null float64\n",
      "fare      300 non-null float64\n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 14.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(test_data_clean.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pclass  sex   age  sibsp  parch     fare\n",
      "0     1.0    1  36.0    0.0    0.0  26.3875\n",
      "1     3.0    0   NaN    8.0    2.0  69.5500\n",
      "2     1.0    1   NaN    0.0    0.0  50.0000\n",
      "3     2.0    1  34.0    0.0    0.0  13.0000\n",
      "4     2.0    1  28.0    0.0    0.0  13.0000\n"
     ]
    }
   ],
   "source": [
    "print(test_data_clean.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 6)\n"
     ]
    }
   ],
   "source": [
    "print(test_data_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass     1.0000\n",
       "sex        1.0000\n",
       "age       36.0000\n",
       "sibsp      0.0000\n",
       "parch      0.0000\n",
       "fare      26.3875\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_clean.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n"
     ]
    }
   ],
   "source": [
    "print(dt.fkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for ix in range(test_data_clean.shape[0]):\n",
    "    # loc (stands for location) is used to fetch row by row for pandas dataframe You cant use indices for pandas\n",
    "    # as in numpy\n",
    "    y_pred.append(dt.predict(test_data_clean.loc[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "# encoding our prediction in numbers\n",
    "y_pred = le.fit_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=y_pred,columns=['survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Answer.csv\",index=True,index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=pd.read_csv(\"Answer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 2)\n"
     ]
    }
   ],
   "source": [
    "print(ans.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
