{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file=pd.read_csv(\"Train.csv\")\n",
    "#print(train_file.columns)\n",
    "#print(train_file.shape)\n",
    "#print(train_file.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['review'], dtype='object')\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "test_file=pd.read_csv(\"Test.csv\")\n",
    "print(test_file.columns)\n",
    "print(test_file.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=test_file.values\n",
    "Y_test=Y_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow. I LOVED the whole series, and am shocked at comments by people who thought it ended badly. Perhaps it waffled a bit in seasons  & , while remaining better than anything else on television. But  and particularly b were beautiful permutations on the themes developed in the more muscular first three seasons. <br /><br />B started with such a sombre mood and Janice's always keen insight into the family angst - that doom-filled line about knowing Tony's penchant for sitting and staring. Anyone who missed the implications of that for the rest of the series does not know Tony. Melfi's discomfort over the psychiatric study and its references to the sociopath's self-deluding sentimentality for pets and animals goes back to the first episodes of the series, say, with Tony's panic attack over the ducks leaving his pool and resonates with Phil's \"wave bye-bye\" line to his grandchildren before the coup de grace of the final episode (not to get into Chase's dark humour).<br /><br />I could go on and on, but I'll just add that I thought the final show - starting with the opening strains of Vanilla Fudge to supply the ironic foreshadow (\"You Keep Me Hangin' On\") to the terminal moments where Tony fades back into complacency with his family in tow or blasts apart like AJ's SUV or Phil's head were, utterly, utterly PERFECT. The best TV ever. <br /><br />Pretty good in a dying medium pathologically supplying the \"jack-off fantasies\" AJ derides (and then into which he promptly subsides). A tip of the pork pie to Mr. Chase.\n"
     ]
    }
   ],
   "source": [
    "print(Y_test[998])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'label'], dtype='object')\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "sampleSubmissiom_file=pd.read_csv(\"Sample_submission.csv\")\n",
    "print(sampleSubmissiom_file.columns)\n",
    "print(sampleSubmissiom_file.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,)\n",
      "(40000,)\n"
     ]
    }
   ],
   "source": [
    "X=train_file.values\n",
    "X_train=X[:,0]\n",
    "print(X_train.shape)\n",
    "Y_train=X[:,1]\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... But it is also Minnie's and Pete's too! Yes, the grumpy captain may not look like Pete, but it is! Mickey and Minnie are the best characters, both of them are very sweet and likable. Interestingly, Minnie is more of a lady in this than what she usually is today and Mickey is less than considerate in this than he is now. Pete is still the same old meanie, but he looks a bit different. <br /><br />In this famous episode, on board a little steamboat, Mickey, Minnie and some side characters have a great deal of fun and a great deal of annoyances. Even in their first appearances, the three main characters are very developed. <br /><br />I quite like this episode, although overall I prefer the Mickey Mouse in the future. I like the animation, the steamboat and music theme, the clever gags - and of course, Mickey and Minnie! <br /><br />Like many early cartoons, this is very random, Walt came up with a very basic plot and just added gags to \"gear\" it along. There is also a parrot side character who is very annoying and rather unnecessary. These are the things I do not like about it. <br /><br />Another interesting thing about this episode, that a colour version has not been made for it (or if it has, I've never heard about it)! <br /><br />Anyone who just enjoys Mickey Mouse and Disney will enjoy this.\n"
     ]
    }
   ],
   "source": [
    "print(X_train[12234])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making given review pos and neg to 1 and 0 respectively\n",
    "for i in range(Y_train.shape[0]):\n",
    "    if Y_train[i]=='pos':\n",
    "        Y_train[i]=1\n",
    "    else:\n",
    "        Y_train[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the X_train data ie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# Init Objects\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "en_stopwords = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "def getCleanReview(review):\n",
    "    \n",
    "    review = review.lower()\n",
    "    review = review.replace(\"<br /><br />\",\" \")\n",
    "    \n",
    "    #Tokenize\n",
    "    tokens = tokenizer.tokenize(review)\n",
    "    new_tokens = [token for token in tokens if token not in en_stopwords]\n",
    "    stemmed_tokens = [ps.stem(token) for token in new_tokens]\n",
    "    \n",
    "    cleaned_review = ' '.join(stemmed_tokens)\n",
    "    \n",
    "    return cleaned_review\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean=[]\n",
    "for i in range(X_train.shape[0]):\n",
    "    #Removing digits from the data\n",
    "    #text = \"The film Pulp Fiction was released in year 1994\"  \n",
    "    X_train[i]=re.sub(r\"\\d\",\"\",X_train[i])  \n",
    "    X_train[i]=re.sub(r\"_\",\"\",X_train[i])\n",
    "    #print(result)\n",
    "    clean_review=getCleanReview(X_train[i])\n",
    "    X_train_clean.append(clean_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http video googl com videoplay docid hl en distribut tri opt mass appeal want best possibl view rang forgo profit continu manual labor job gladli entertain work view texa tale pleas write like like alex like stuie texa texa tale write opinion rule\n"
     ]
    }
   ],
   "source": [
    "print(X_train_clean[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(Y_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_clean=[]\n",
    "for i in range(Y_test.shape[0]):\n",
    "    #Removing digits from the data\n",
    "    #text = \"The film Pulp Fiction was released in year 1994\"  \n",
    "    Y_test[i]=re.sub(r\"\\d\",\"\",Y_test[i])  \n",
    "    Y_test[i]=re.sub(r\"_\",\"\",Y_test[i])\n",
    "    #print(result)\n",
    "    clean_test=getCleanReview(Y_test[i])\n",
    "    Y_test_clean.append(clean_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rememb old kung fu movi use watch friday saturday late night babysitt thought charg well movi play exactli like one movi patsi kensit biggest claim fame love interest mel gibson charact lethal weapon perform one reason never made big terribl actress lethal weapon thought cute cute enough check movi includ love music love danc anoth big let obvious impress either attract eye soul scream turn play anoth cheap predict role done badli movi kensit star comedienn good one either work club franc cut homeland make ear bleed luck even wors french govern want throw expir visa mayb caught act get marri casanova freiss luck predict begin terribl way give movi neg rate star rate\n"
     ]
    }
   ],
   "source": [
    "print(Y_test_clean[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 64045)\n"
     ]
    }
   ],
   "source": [
    "x_vec = cv.fit_transform(X_train_clean)\n",
    "#print(cv.get_feature_names())\n",
    "\n",
    "#print(x_vec)\n",
    "print(x_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 64045)\n"
     ]
    }
   ],
   "source": [
    "y_vec = cv.transform(Y_test_clean)\n",
    "#print(cv.get_feature_names())\n",
    "\n",
    "#print(x_vec)\n",
    "print(y_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using MultiNomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=list(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(x_vec,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=mnb.predict(y_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8905\n"
     ]
    }
   ],
   "source": [
    "print(mnb.score(x_vec,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label=[]\n",
    "for i in range(len(prediction)):\n",
    "    if prediction[i]==1:\n",
    "        Label.append(\"pos\")\n",
    "    else:\n",
    "        Label.append(\"neg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label=np.array(Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(Label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label=Label.reshape((10000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['neg']\n",
      " ['neg']\n",
      " ['neg']\n",
      " ...\n",
      " ['pos']\n",
      " ['pos']\n",
      " ['neg']]\n"
     ]
    }
   ],
   "source": [
    "print(Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=Label,columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"MovieRatingAnswer.csv\",index=True,index_label=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=pd.read_csv(\"MovieRatingAnswer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n",
      "Index(['Id', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(answer.shape)\n",
    "print(answer.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
